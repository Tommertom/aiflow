{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for AIFlow class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "API_KEY=os.getenv(\"API_KEY\")\n",
    "from aiflow import AIFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just an empty flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow1 = AIFlow(api_key=API_KEY,model=\"gpt-3.5-turbo\",max_tokens=3000, temperature=0)\n",
    "(\n",
    "    flow1\n",
    "    .show_model_config()\n",
    "    .show_self_data()\n",
    "    .pretty_print_messages()\n",
    "    .pretty_print_messages_to_file(file_name=\"nothing.txt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot=AIFlow(api_key=API_KEY,model=\"gpt-3.5-turbo\",max_tokens=3000, temperature=1)\n",
    "chatbot.show_model_config().show_self_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(    chatbot\n",
    "        .show_model_config()\n",
    "        .set_system_prompt(\"You are a helpful cooking assistant always eager to give a recipe for whatever the user says.\")\n",
    "        .add_user_chat(\"How is the weather here?\")\n",
    "        .show_self_data()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.add_user_chat(\"Ok. Give me a recipe inspired by weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.latest_to_context(\"dish\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.show_self_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.reduce_messages_to_text(lambda x: (print(x), \"Replacing latest with all sorts of nothing\")[1]).show_self_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.filter_messages(lambda items: [{**item, \"content\": \"You are an artist very good in poetry\"} if item.get(\"role\") == \"system\" else item for item in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.show_self_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just completions - no chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.completion(\"Give me 10 random names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.show_self_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.completion(\"Give the following names in reverse order: [latest].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some context manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.show_self_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.set_context(content=\"Nothing\", label=\"stuff\").show_self_data().delete_context(label=\"stuff\").show_self_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.read_textfile_to_context(filename=\"output.txt\").show_self_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining AIFlows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's say you are a random person hungry for food. What would you like to eat?\n",
      "\n",
      "I would probably go for a classic cheeseburger with fries or maybe some pizza. Those are always reliable options for satisfying hunger.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aiflow.AIFlow at 0x20f019cedd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otherbot=AIFlow(api_key=API_KEY,model=\"gpt-3.5-turbo\",max_tokens=3000, temperature=1)\n",
    "otherbot.completion(\"Let's say you are a random person hungry for food. What would you like to eat?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would probably go for a classic cheeseburger with fries or maybe some pizza. Those are always reliable options for satisfying hunger.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otherbot.return_latest_to_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Messages:\n",
      "[]\n",
      "\n",
      "Context Map:\n",
      "{\n",
      "    \"food_choice\": \"I would probably go for a classic cheeseburger with fries or maybe some pizza. Those are always reliable options for satisfying hunger.\"\n",
      "}\n",
      "\n",
      "Images Map:\n",
      "{}\n",
      "\n",
      "Audio Map:\n",
      "{}\n",
      "Give a silly comment on the following choice of food: [food_choice]\n",
      "\n",
      "Why not both? Cheeseburger pizza! Double the deliciousness, double the fun!\n",
      "\n",
      "Chat Messages:\n",
      "[]\n",
      "\n",
      "Context Map:\n",
      "{\n",
      "    \"food_choice\": \"I would probably go for a classic cheeseburger with fries or maybe some pizza. Those are always reliable options for satisfying hunger.\",\n",
      "    \"latest\": \"Why not both? Cheeseburger pizza! Double the deliciousness, double the fun!\"\n",
      "}\n",
      "\n",
      "Images Map:\n",
      "{}\n",
      "\n",
      "Audio Map:\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aiflow.AIFlow at 0x20f01d602b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sillybot=AIFlow(api_key=API_KEY,model=\"gpt-3.5-turbo\",max_tokens=3000, temperature=1)\n",
    "sillybot.set_context(content=otherbot.return_latest_to_text(), label=\"food_choice\").show_self_data()\n",
    "sillybot.completion(prompt=\"Give a silly comment on the following choice of food: [food_choice]\").show_self_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using vectordatabase Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.trychroma.com/guides\n",
    "import chromadb\n",
    "chroma_client = chromadb.Client() # chromadb.PersistentClient(path=\"/path/to/save/to\")\n",
    "collection = chroma_client.create_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[\n",
    "        \"This is a document about pineapple\",\n",
    "        \"This is a document about oranges\"\n",
    "    ],\n",
    "    ids=[\"id1\", \"id2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id1', 'id2']], 'distances': [[1.0404009819030762, 1.2430799007415771]], 'metadatas': [[None, None]], 'embeddings': None, 'documents': [['This is a document about pineapple', 'This is a document about oranges']], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"This is a query document about hawaii\"], # Chroma will embed this for you\n",
    "    n_results=1 # how many results to return\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.peek() # returns a list of the first 10 items in the collection\n",
    "collection.count() # returns the number of items in the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a document about pineapple\n",
      "This is a document about oranges\n"
     ]
    }
   ],
   "source": [
    "print(chroma_query_result_to_text(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something really silly about this random text: [found_doc]\n",
      "\n",
      "But don't get it twisted, we're not comparing apples to oranges, we're comparing pineapples to oranges!\n",
      "\n",
      "Chat Messages:\n",
      "[]\n",
      "\n",
      "Context Map:\n",
      "{\n",
      "    \"food_choice\": \"I would probably go for a classic cheeseburger with fries or maybe some pizza. Those are always reliable options for satisfying hunger.\",\n",
      "    \"latest\": \"But don't get it twisted, we're not comparing apples to oranges, we're comparing pineapples to oranges!\",\n",
      "    \"found_doc\": \"This is a document about pineapple\\nThis is a document about oranges\"\n",
      "}\n",
      "\n",
      "Images Map:\n",
      "{}\n",
      "\n",
      "Audio Map:\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aiflow.AIFlow at 0x20f01d602b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sillybot.set_context(content=chroma_query_result_to_text(results), label=\"found_doc\")\n",
    "sillybot.completion(\"Say something really silly about this random text: [found_doc]\").show_self_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
